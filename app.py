import streamlit as st
import pandas as pd
import zipfile
import os
from io import BytesIO
import traceback
import re

from openpyxl import load_workbook  # <- c·∫ßn thi·∫øt cho x·ª≠ l√Ω c√¥ng th·ª©c

st.set_page_config(page_title="T·∫°o File H·∫°ch To√°n", layout="wide")
st.title("üìã T·∫°o File H·∫°ch To√°n Chu·∫©n t·ª´ Excel")
tab1, tab2, tab3 = st.tabs([
    "üßæ T·∫°o File H·∫°ch To√°n", 
    "üîç So s√°nh v√† Xo√° d√≤ng tr√πng",
    "üìä File tu·ª≥ ch·ªânh (Check th·ªß c√¥ng)"
])

with tab1:
    uploaded_file = st.file_uploader("üìÇ Ch·ªçn file Excel (.xlsx)", type=["xlsx"])
    
    def extract_month_year_from_filename(filename):
        try:
            match = re.search(r'(\d{4})[\.\-_]?\s*(\d{2})|\s*(\d{2})[\.\-_]?\s*(\d{4})', filename)
            if match:
                year = match.group(1) or match.group(4)
                month = match.group(2) or match.group(3)
                return month, year
            else:
                return "T·ª± ƒë·∫∑t t√™n nh√©", "T·ª± ƒë·∫∑t t√™n nh√©"
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω t√™n file: {str(e)}")
            return "T·ª± ƒë·∫∑t t√™n nh√©", "T·ª± ƒë·∫∑t t√™n nh√©"
    
    def to_ddmmyyyy(date_val):
        try:
            if pd.isnull(date_val):
                return ""
            if isinstance(date_val, pd.Timestamp):
                return date_val.strftime("%d/%m/%Y")
            if isinstance(date_val, float) or isinstance(date_val, int):
                return pd.to_datetime(date_val, origin='1899-12-30', unit='D').strftime("%d/%m/%Y")
            if isinstance(date_val, str):
                parsed = pd.to_datetime(date_val, dayfirst=True, errors='coerce')
                if pd.isnull(parsed):
                    parsed = pd.to_datetime(date_val, errors='coerce')
                return parsed.strftime("%d/%m/%Y") if not pd.isnull(parsed) else ""
            return str(date_val)
        except:
            return ""

    if uploaded_file:
        try:
            file_name = uploaded_file.name
            thang, nam = extract_month_year_from_filename(file_name)
            if thang != "T·ª± ƒë·∫∑t t√™n nh√©" and nam != "T·ª± ƒë·∫∑t t√™n nh√©":
                st.success(f"ƒê√£ t·ª± ƒë·ªông l·∫•y th√°ng: {thang} v√† nƒÉm: {nam} t·ª´ t√™n file {file_name}")
            else:
                st.error("Kh√¥ng th·ªÉ x√°c ƒë·ªãnh th√°ng v√† nƒÉm t·ª´ t√™n file. Vui l√≤ng ki·ªÉm tra l·∫°i t√™n file.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω file t·∫£i l√™n: {str(e)}")
            thang, nam = "T·ª± ƒë·∫∑t t√™n nh√©", "T·ª± ƒë·∫∑t t√™n nh√©"
    else:
        thang, nam = "T·ª± ƒë·∫∑t t√™n nh√©", "T·ª± ƒë·∫∑t t√™n nh√©"

    chu_hau_to = st.text_input("‚úçÔ∏è H·∫≠u t·ªë ch·ª©ng t·ª´ (VD: A, B1, NV123)").strip().upper()
    prefix = f"T{thang}_{nam}" if thang != "T·ª± ƒë·∫∑t t√™n nh√©" and nam != "T·ª± ƒë·∫∑t t√™n nh√©" else "TBD"

    def classify_department(value, content_value=None):
        try:
            val = str(value).upper()
            if "VACCINE" in val or "VACXIN" in val:
                return "VACCINE"
            elif "THU·ªêC" in val:
                return "THUOC"
            elif "TH·∫∫" in val:
                return "THE"
            if content_value:
                content_val = str(content_value).upper()
                if "VACCINE" in content_val:
                    return "VACCINE"
                elif "THU·ªêC" in content_val:
                    return "THUOC"
                elif "TH·∫∫" in content_val:
                    return "THE"
        except:
            pass
        return "KCB"

    category_info = {
        "KCB": {"ma": "KHACHLE01", "ten": "Kh√°ch h√†ng l·∫ª - Kh√°m ch·ªØa b·ªánh"},
        "THUOC": {"ma": "KHACHLE02", "ten": "Kh√°ch h√†ng l·∫ª - B√°n thu·ªëc"},
        "VACCINE": {"ma": "KHACHLE03", "ten": "Kh√°ch h√†ng l·∫ª - Ti√™m vacxin"},
        "THE": {"ma": "KHACHLE04", "ten": "Kh√°ch h√†ng l·∫ª - Tr·∫£ th·∫ª"}
    }

    output_columns = [
        "Ng√†y h·∫°ch to√°n (*)", "Ng√†y ch·ª©ng t·ª´ (*)", "S·ªë ch·ª©ng t·ª´ (*)",
        "M√£ ƒë·ªëi t∆∞·ª£ng", "T√™n ƒë·ªëi t∆∞·ª£ng", "N·ªôp v√†o TK", "M·ªü t·∫°i ng√¢n h√†ng",
        "L√Ω do thu", "Di·ªÖn gi·∫£i l√Ω do thu", "Di·ªÖn gi·∫£i (h·∫°ch to√°n)",
        "TK N·ª£ (*)", "TK C√≥ (*)", "S·ªë ti·ªÅn"
    ]

    def format_name(name):
        try:
            clean = re.split(r'[\n\r\t\u00A0\u2003]+', str(name).strip())[0]
            clean = re.sub(r'\s+', ' ', clean)
            return clean.replace("-", "").title()
        except:
            return str(name)

    def gen_so_chung_tu(date_str, category):
        try:
            d, m, y = date_str.split("/")
            return f"NVK{category}{d.zfill(2)}{m.zfill(2)}{y}{chu_hau_to}"
        except:
            return f"NVK_INVALID_{chu_hau_to}"

    if st.button("üöÄ T·∫°o File Zip") and uploaded_file and chu_hau_to:
        try:
            xls = pd.ExcelFile(uploaded_file)
            st.success(f"üì• ƒê√£ ƒë·ªçc th√†nh c√¥ng file {uploaded_file.name} v·ªõi {len(xls.sheet_names)} sheet. ƒêang x·ª≠ l√Ω, vui l√≤ng ƒë·ª£i...")
            data_by_category = {k: {} for k in category_info}
            logs = []

            try:
                has_pos = int(nam) <= 2022
            except:
                has_pos = True

            for sheet_name in xls.sheet_names:
                if not sheet_name.replace(".", "", 1).isdigit() and not sheet_name.replace(",", "", 1).isdigit():
                    logs.append(f"‚è© B·ªè qua sheet kh√¥ng h·ª£p l·ªá: {sheet_name}")
                    continue

                df = xls.parse(sheet_name)
                df.columns = [str(col).strip().upper() for col in df.columns]

                if "KHOA/B·ªò PH·∫¨N" not in df.columns or "TI·ªÄN M·∫∂T" not in df.columns:
                    logs.append(f"‚ö†Ô∏è Sheet {sheet_name} thi·∫øu c·ªôt c·∫ßn thi·∫øt.")
                    continue

                date_column = 'NG√ÄY QU·ª∏' if 'NG√ÄY QU·ª∏' in df.columns else 'NG√ÄY KH√ÅM'
                if date_column not in df.columns:
                    logs.append(f"‚ö†Ô∏è Sheet {sheet_name} thi·∫øu c·ªôt ng√†y ({date_column})")
                    continue

                df["TI·ªÄN M·∫∂T"] = pd.to_numeric(df["TI·ªÄN M·∫∂T"], errors="coerce")
                df = df[df["TI·ªÄN M·∫∂T"].notna() & (df["TI·ªÄN M·∫∂T"] != 0)]
                df = df[df[date_column].notna() & (df[date_column] != "-")]
                df = df[df["H·ªå V√Ä T√äN"].notna() & (df["H·ªå V√Ä T√äN"] != "-")]

                df["CATEGORY"] = df.apply(lambda row: classify_department(row["KHOA/B·ªò PH·∫¨N"], row.get("N·ªòI DUNG THU")), axis=1)

                for category in data_by_category:
                    cat_df = df[df["CATEGORY"] == category]
                    if cat_df.empty:
                        continue

                    for mode in ["PT", "PC"]:
                        is_pt = mode == "PT"
                        df_mode = cat_df[cat_df["TI·ªÄN M·∫∂T"] > 0] if is_pt else cat_df[cat_df["TI·ªÄN M·∫∂T"] < 0]
                        if df_mode.empty:
                            continue

                        df_mode = df_mode.reset_index(drop=True)

                        out_df = pd.DataFrame()
                        out_df["Ng√†y h·∫°ch to√°n (*)"] = df_mode[date_column].apply(to_ddmmyyyy)
                        out_df["Ng√†y ch·ª©ng t·ª´ (*)"] = out_df["Ng√†y h·∫°ch to√°n (*)"]
                        out_df["S·ªë ch·ª©ng t·ª´ (*)"] = out_df["Ng√†y ch·ª©ng t·ª´ (*)"].apply(lambda x: gen_so_chung_tu(x, category))
                        out_df["M√£ ƒë·ªëi t∆∞·ª£ng"] = category_info[category]["ma"]
                        out_df["T√™n ƒë·ªëi t∆∞·ª£ng"] = df_mode["H·ªå V√Ä T√äN"].apply(format_name)
                        out_df["N·ªôp v√†o TK"] = "1290153594"
                        out_df["M·ªü t·∫°i ng√¢n h√†ng"] = "Ng√¢n h√†ng TMCP ƒê·∫ßu t∆∞ v√† Ph√°t tri·ªÉn Vi·ªát Nam - Ho√†ng Mai"
                        out_df["L√Ω do thu"] = ""

                        try:
                            ten_dv = category_info[category]['ten'].split('-')[-1].strip().lower()
                            pos_phrase = " qua pos" if has_pos else ""
                            out_df["Di·ªÖn gi·∫£i l√Ω do thu"] = (
                                ("Thu ti·ªÅn" if is_pt else "Chi ti·ªÅn") +
                                f" {ten_dv}{pos_phrase} ng√†y " + out_df["Ng√†y ch·ª©ng t·ª´ (*)"]
                            )
                            out_df["TK N·ª£ (*)"] = "1368" if has_pos else "1121"
                        except:
                            out_df["Di·ªÖn gi·∫£i l√Ω do thu"] = ""
                            out_df["TK N·ª£ (*)"] = ""

                        out_df["Di·ªÖn gi·∫£i (h·∫°ch to√°n)"] = out_df["Di·ªÖn gi·∫£i l√Ω do thu"] + " " + df_mode["H·ªå V√Ä T√äN"].apply(format_name)
                        out_df["TK C√≥ (*)"] = "131"
                        out_df["S·ªë ti·ªÅn"] = df_mode["TI·ªÄN M·∫∂T"].abs().apply(lambda x: f"=VALUE({x})")

                        out_df = out_df.astype(str)
                        out_df = out_df[output_columns]

                        data_by_category[category].setdefault(sheet_name, {})[mode] = out_df
                        logs.append(f"‚úÖ {sheet_name} ({category}) [{mode}]: {len(out_df)} d√≤ng")

            if all(not sheets for sheets in data_by_category.values()):
                st.warning("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi l·ªçc.")
            else:
                zip_buffer = BytesIO()
                with zipfile.ZipFile(zip_buffer, "w") as zip_file:
                    for category, sheets in data_by_category.items():
                        for day, data in sheets.items():
                            output = BytesIO()
                            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                                for mode in ["PT", "PC"]:
                                    if mode in data and not data[mode].empty:
                                        full_df = data[mode]
                                        chunks = [full_df[i:i+500] for i in range(0, len(full_df), 500)]
                                        for idx, chunk in enumerate(chunks):
                                            sheet_name = mode if idx == 0 else f"{mode} {idx + 1}"
                                            chunk.to_excel(writer, sheet_name=sheet_name, index=False)

                                            workbook = writer.book
                                            worksheet = writer.sheets[sheet_name]
                                            header_format = workbook.add_format({
                                                'bold': True, 'bg_color': '#D9E1F2', 'border': 1
                                            })

                                            for col_num, col_name in enumerate(chunk.columns):
                                                worksheet.write(0, col_num, col_name, header_format)

                                            for i, col in enumerate(chunk.columns):
                                                max_width = max([len(str(col))] + [len(str(v)) for v in chunk[col].values])
                                                worksheet.set_column(i, i, max_width + 2)

                                            worksheet.set_tab_color('#92D050')
                            output.seek(0)
                            zip_path = f"{prefix}_{category}/{day.replace(',', '.').strip()}.xlsx"
                            zip_file.writestr(zip_path, output.read())
                
                # üîÅ L√†m s·∫°ch c√¥ng th·ª©c =VALUE(...) v√† t·∫°o file s·∫°ch
                cleaned_zip = BytesIO()
                with zipfile.ZipFile(zip_buffer, "r") as zin, zipfile.ZipFile(cleaned_zip, "w") as zout:
                    for item in zin.infolist():
                        if item.filename.endswith(".xlsx"):
                            with zin.open(item.filename) as f:
                                wb = load_workbook(f, data_only=False)
                                for sheet in wb.worksheets:
                                    headers = [cell.value for cell in sheet[1]]
                                    if "S·ªë ti·ªÅn" in headers:
                                        col_idx = headers.index("S·ªë ti·ªÅn") + 1
                                        for row in sheet.iter_rows(min_row=2, min_col=col_idx, max_col=col_idx):
                                            cell = row[0]
                                            if cell.data_type == "f" and isinstance(cell.value, str):
                                                match = re.search(r"=VALUE\(([\d.]+)\)", cell.value)
                                                if match:
                                                    cell.value = float(match.group(1))
                                                    cell.data_type = 'n'

                                temp_output = BytesIO()
                                wb.save(temp_output)
                                temp_output.seek(0)
                                zout.writestr(item.filename, temp_output.read())
                        else:
                            zout.writestr(item, zin.read(item.filename))

                st.success("üéâ ƒê√£ x·ª≠ l√Ω xong!")
                st.download_button("üì¶ T·∫£i File Zip Ho√†n Ch·ªânh", data=cleaned_zip.getvalue(), file_name=f"{prefix}.zip")

            st.markdown("### üìÑ Nh·∫≠t k√Ω x·ª≠ l√Ω")
            st.markdown("\n".join([f"- {line}" for line in logs]))

        except Exception as e:
            st.error("‚ùå ƒê√£ x·∫£y ra l·ªói:")
            st.code(traceback.format_exc(), language="python")

# ======= TAB 2: SO S√ÅNH XO√Å TR√ôNG =======
with tab2:
    st.header("üîç So s√°nh v·ªõi File G·ªëc v√† Xo√° d√≤ng tr√πng")

    base_file = st.file_uploader("üìÇ File G·ªëc (Base - Excel)", type=["xlsx"], key="base_file")
    zip_compare_file = st.file_uploader("üì¶ File ZIP ƒë·∫ßu ra c·ªßa h·ªá th·ªëng", type=["zip"], key="zip_compare")

    def normalize_name(name):
        try:
            name = str(name).strip().lower()
            name = re.sub(r'\s+', ' ', name)
            return name
        except:
            return str(name)

    def normalize_date(date_val):
        try:
            if pd.isna(date_val) or str(date_val).strip() in ["", "-", "NaT", "NaN"]:
                return None
            if isinstance(date_val, str):
                date_val = pd.to_datetime(date_val, dayfirst=True, errors="coerce")
            return date_val.strftime("%d/%m/%Y") if pd.notna(date_val) else None
        except:
            return None

    def normalize_columns(columns):
        return [
            str(c).strip()
            .replace('\xa0', ' ')
            .replace('\n', ' ')
            .replace('\t', ' ')
            .replace('\r', ' ')
            .strip()
            .title()
        for c in columns
    ]

    def extract_type_from_path(path):
        path = path.upper()
        if "KCB" in path:
            return "Kh√°m ch·ªØa b·ªánh"
        elif "THUOC" in path:
            return "Thu·ªëc"
        elif "VACCINE" in path:
            return "Vaccine"
        elif "THE" in path:
            return "Th·∫ª"
        return "Kh√°c"

    if st.button("üö´ Xo√° d√≤ng tr√πng theo T√™n + Ng√†y"):
        if base_file and zip_compare_file:
            try:
                base_df = pd.read_excel(base_file)
                base_df.columns = normalize_columns(base_df.columns)

                required_cols = {"T√™n ƒê·ªëi T∆∞·ª£ng", "Ng√†y H·∫°ch To√°n", "Ph√°t Sinh N·ª£"}
                missing_cols = required_cols - set(base_df.columns)

                if missing_cols:
                    st.error(f"""‚ùå File g·ªëc **{base_file.name}** thi·∫øu c·ªôt: {', '.join(missing_cols)}
üîç C√°c c·ªôt hi·ªán c√≥: {', '.join(base_df.columns)}""")
                    st.stop()

                base_df["T√™n chu·∫©n"] = base_df["T√™n ƒê·ªëi T∆∞·ª£ng"].apply(normalize_name)
                base_df["Ng√†y chu·∫©n"] = base_df["Ng√†y H·∫°ch To√°n"].apply(normalize_date)
                base_df = base_df[base_df["T√™n chu·∫©n"].notna() & base_df["Ng√†y chu·∫©n"].notna()]
                base_lookup = base_df.set_index(["T√™n chu·∫©n", "Ng√†y chu·∫©n"])["Ph√°t Sinh N·ª£"].to_dict()

                base_pairs = set(base_lookup.keys())

                zip_in = zipfile.ZipFile(zip_compare_file, 'r')
                zip_namelist = [fn for fn in zip_in.namelist() if fn.lower().endswith(".xlsx")]
                total_files = len(zip_namelist)
                zip_buffer = BytesIO()

                progress = st.progress(0, text="üöß ƒêang x·ª≠ l√Ω ZIP...")
                logs = []
                total_removed = 0
                matched_rows_summary = []

                with zipfile.ZipFile(zip_buffer, "w") as zip_out:
                    for idx, file_name in enumerate(zip_namelist):
                        with zip_in.open(file_name) as f:
                            xls = pd.ExcelFile(f)
                            output = BytesIO()
                            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                                for sheet in xls.sheet_names:
                                    df = pd.read_excel(xls, sheet_name=sheet)
                                    df.columns = normalize_columns(df.columns)

                                    if "T√™n ƒê·ªëi T∆∞·ª£ng" in df.columns and "Ng√†y H·∫°ch To√°n (*)" in df.columns and "S·ªë Ti·ªÅn" in df.columns:
                                        df["T√™n chu·∫©n"] = df["T√™n ƒê·ªëi T∆∞·ª£ng"].apply(normalize_name)
                                        df["Ng√†y chu·∫©n"] = df["Ng√†y H·∫°ch To√°n (*)"].apply(normalize_date)
                                        df["STT G·ªëc"] = df.index

                                        df["Tr·∫°ng th√°i"] = df.apply(
                                            lambda row: "Tr√πng ho√†n to√†n" if (row["T√™n chu·∫©n"], row["Ng√†y chu·∫©n"]) in base_pairs else "Kh√¥ng tr√πng",
                                            axis=1
                                        )

                                        matched = df[df["Tr·∫°ng th√°i"] == "Tr√πng ho√†n to√†n"]
                                        removed = len(matched)
                                        total_removed += removed

                                        if not matched.empty:
                                            temp_matched = matched.copy()
                                            temp_matched["Lo·∫°i"] = extract_type_from_path(file_name)
                                            temp_matched["Sheet"] = sheet
                                            temp_matched["Ph√°t Sinh N·ª£ (File G·ªëc)"] = temp_matched.apply(
                                                lambda row: base_lookup.get((row["T√™n chu·∫©n"], row["Ng√†y chu·∫©n"])), axis=1
                                            )
                                            matched_rows_summary.append(
                                                temp_matched[[
                                                    "Lo·∫°i", "Sheet", "STT G·ªëc", "T√™n ƒê·ªëi T∆∞·ª£ng",
                                                    "Ng√†y H·∫°ch To√°n (*)", "S·ªë Ti·ªÅn", "Ph√°t Sinh N·ª£ (File G·ªëc)"
                                                ]]
                                            )
                                            logs.append(f"- üìÑ `{file_name}` | Sheet: `{sheet}` üëâ ƒê√£ xo√° {removed} d√≤ng")

                                        df = df[df["Tr·∫°ng th√°i"] != "Tr√πng ho√†n to√†n"]
                                        df.drop(columns=["T√™n chu·∫©n", "Ng√†y chu·∫©n", "Tr·∫°ng th√°i"], inplace=True)

                                    df.to_excel(writer, sheet_name=sheet, index=False)

                                    workbook = writer.book
                                    worksheet = writer.sheets[sheet]
                                    header_format = workbook.add_format({
                                        'bold': True, 'bg_color': '#FFE699', 'border': 1
                                    })

                                    for col_num, col_name in enumerate(df.columns):
                                        worksheet.write(0, col_num, col_name, header_format)
                                        max_width = max([len(str(col_name))] + [len(str(v)) for v in df[col_name]])
                                        worksheet.set_column(col_num, col_num, max_width + 2)

                                    worksheet.set_tab_color("#FFC000")

                            output.seek(0)
                            zip_out.writestr(file_name, output.read())

                        progress.progress((idx + 1) / total_files, text=f"‚úÖ ƒê√£ x·ª≠ l√Ω {idx + 1}/{total_files} file")

                st.session_state["matched_rows_summary"] = matched_rows_summary
                st.session_state["logs"] = logs
                st.session_state["zip_buffer"] = zip_buffer.getvalue()
                st.session_state["zip_ready"] = True

                st.success(f"üéâ ƒê√£ xo√° t·ªïng c·ªông {total_removed} d√≤ng tr√πng trong {total_files} file Excel.")

            except Exception as e:
                st.error("‚ùå L·ªói khi x·ª≠ l√Ω ZIP:")
                st.code(traceback.format_exc(), language="python")

# üëá LOG chi ti·∫øt
if "logs" in st.session_state:
    st.subheader("üìú Log chi ti·∫øt ƒë√£ x·ª≠ l√Ω")
    for log in st.session_state["logs"]:
        st.markdown(log)

# üëá B·∫¢NG preview + b·ªô l·ªçc
if "matched_rows_summary" in st.session_state and st.session_state["matched_rows_summary"]:
    st.subheader("üìä D√≤ng tr√πng ƒë√£ xo√° (T√™n + Ng√†y):")
    combined_df = pd.concat(st.session_state["matched_rows_summary"], ignore_index=True)

    # B·ªô l·ªçc
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        filter_type = st.selectbox("üîç L·ªçc theo Lo·∫°i", ["T·∫•t c·∫£"] + sorted(combined_df["Lo·∫°i"].unique()))
    with col2:
        filter_sheet = st.selectbox("üìÑ L·ªçc theo Sheet", ["T·∫•t c·∫£"] + sorted(combined_df["Sheet"].unique()))
    with col3:
        filter_name = st.text_input("üßç L·ªçc theo T√™n ch·ª©a", "")
    with col4:
        filter_date = st.text_input("üìÖ L·ªçc theo Ng√†y H·∫°ch To√°n", "")

    # √Åp d·ª•ng filter
    filtered_df = combined_df.copy()
    if filter_type != "T·∫•t c·∫£":
        filtered_df = filtered_df[filtered_df["Lo·∫°i"] == filter_type]
    if filter_sheet != "T·∫•t c·∫£":
        filtered_df = filtered_df[filtered_df["Sheet"] == filter_sheet]
    if filter_name.strip():
        filtered_df = filtered_df[filtered_df["T√™n ƒê·ªëi T∆∞·ª£ng"].str.contains(filter_name.strip(), case=False, na=False)]
    if filter_date.strip():
        filtered_df = filtered_df[filtered_df["Ng√†y H·∫°ch To√°n (*)"].astype(str).str.contains(filter_date.strip())]

    st.dataframe(filtered_df)

# üëá Button t·∫£i file
if "zip_buffer" in st.session_state and st.session_state["zip_ready"]:
    st.download_button(
        "üì• T·∫£i file ZIP ƒë√£ xo√° d√≤ng tr√πng",
        data=st.session_state["zip_buffer"],
        file_name="output_cleaned.zip"
    )

with tab3:
    st.header("üìä G·ªôp D·ªØ Li·ªáu Th√°ng Th√†nh 1 File Excel T·ªïng H·ª£p")
    zip_input = st.file_uploader("üìÇ T·∫£i l√™n file Zip ƒë·∫ßu ra t·ª´ Tab 1", type=["zip"], key="zip_monthly")

    if zip_input:
        try:
            group_data = {
                "PT_KCB": [], "PC_KCB": [],
                "PT_THUOC": [], "PC_THUOC": [],
                "PT_VACCINE": [], "PC_VACCINE": []
            }

            # üß† L·∫•y t√™n th√°ng & nƒÉm t·ª´ file zip n·∫øu c√≥ th·ªÉ
            match = re.search(r't(\d{1,2})[_\-\.](\d{4})', zip_input.name.lower())
            if match:
                thang_text = f"T{int(match.group(1))}"
                nam_text = match.group(2)
            else:
                thang_text = "TBD"
                nam_text = "XXXX"

            with zipfile.ZipFile(zip_input, "r") as zipf:
                for filename in zipf.namelist():
                    if not filename.endswith(".xlsx"):
                        continue

                    with zipf.open(filename) as f:
                        xls = pd.ExcelFile(f)
                        for sheet_name in xls.sheet_names:
                            if sheet_name.startswith("PT") or sheet_name.startswith("PC"):
                                df = xls.parse(sheet_name)
                                if not set(["Ng√†y ch·ª©ng t·ª´ (*)", "T√™n ƒë·ªëi t∆∞·ª£ng", "S·ªë ti·ªÅn"]).issubset(df.columns):
                                    continue

                                short_type = None
                                if "KCB" in filename.upper():
                                    short_type = "KCB"
                                elif "THUOC" in filename.upper():
                                    short_type = "THUOC"
                                elif "VACCINE" in filename.upper():
                                    short_type = "VACCINE"
                                else:
                                    continue

                                mode = "PT" if sheet_name.startswith("PT") else "PC"
                                key = f"{mode}_{short_type}"

                                df_filtered = df[["Ng√†y ch·ª©ng t·ª´ (*)", "T√™n ƒë·ªëi t∆∞·ª£ng", "S·ªë ti·ªÅn"]].copy()
                                group_data[key].append(df_filtered)

            output = BytesIO()
            with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                for key, df_list in group_data.items():
                    if not df_list:
                        continue
                    merged_df = pd.concat(df_list, ignore_index=True)
                    merged_df.columns = ["Ng√†y", "T√™n", "S·ªë ti·ªÅn"]

                    # Th√™m c√¥ng th·ª©c c·ªôt Ghi ch√∫
                    merged_df["Ghi ch√∫"] = ""

                    merged_df.to_excel(writer, sheet_name=key, index=False, startrow=0, header=True)

                    workbook = writer.book
                    worksheet = writer.sheets[key]

                    # Format header
                    header_format = workbook.add_format({'bold': True, 'bg_color': '#FCE4D6', 'border': 1})
                    for col_num, value in enumerate(merged_df.columns):
                        worksheet.write(0, col_num, value, header_format)
                        max_width = max(len(str(value)), *(merged_df.iloc[:, col_num].astype(str).map(len)))
                        worksheet.set_column(col_num, col_num, max_width + 2)

                    # Vi·∫øt c√¥ng th·ª©c Ghi ch√∫
                    for row_num in range(1, len(merged_df)+1):
                        formula = f'=IF(COUNTIFS(A:A,A{row_num+1},B:B,B{row_num+1},C:C,C{row_num+1})>1,"L·∫∑p","")'
                        worksheet.write_formula(row_num, 3, formula)

                    worksheet.set_tab_color("#FFD966")

            file_name_out = f"TongHop_{thang_text}_{nam_text}.xlsx"
            st.success(f"üéâ ƒê√£ g·ªôp xong d·ªØ li·ªáu th√°ng {thang_text}/{nam_text}!")
            st.download_button("üì• T·∫£i File T·ªïng H·ª£p", data=output.getvalue(), file_name=file_name_out)

        except Exception as e:
            st.error("‚ùå L·ªói khi x·ª≠ l√Ω file Zip:")
            st.code(traceback.format_exc(), language="python")
